## Capstone Project ##

During my second-to-last semester of classes at UVic, I participated in a capstone project featuring cross-disciplinary Biomedical, Electrical, and Software engineering work.

The video showing the final prototype as well as covering the basics can be found at <https://youtu.be/hSBkPvvHydw>.  The video itself serves as a good introduction to the scope of the project and what was ultimately accomplished, but to briefly summarize: the goal of the project was to build a rigid prosthetic gauntlet capable of self-contained motion capture via potentiometer readings with the goal that technology like this could be used as an analog-digital bridge for sign language users in a wide variety of environments.  To demonstrate some of the potential uses of this technology, a simple Unity program rendering motion in real-time and a simple machine learning program which could recognize basic hand positions were created.  

### What I did ##

My role within the project team was primarily to develop a the simple Unity program to render the hand positions as I was receiving input from the gauntlets.  I also assisted with several other engineering components such as putting together the first 3D printed prototypes and helping to develop the actual program for reading and processing potentiometer inputs from the gauntlet as well as administrative components such as organizing and hosting team meetings, as most of my program work necessitated the existence of a fully functioning and wired gauntlet to use as a reference.

### Reflections on the project ###

Overall, I felt that the project went well and I was proud of what we accomplished.  Despite that, there are many things which I believe could have been handled better.  I think that the prototyping of the 3D printing of the gauntlets should have been happened faster so that the rest of the project, which was almost completely dependent upon that, could have had more time.  A lot of this came down to factors outside of our control with access to UVic and private 3D printers and the restrictions of the COVID-19 pandemic, but it still would have been something I would have like to seen done better.  As well, my personal contributions to the Unity program were not of a particularly high coding standard.  The Unity program itself simply polled the most recent potentiometer values from a shared file with the program reading and interpreting the gauntlet's inputs.  From there, rough measured heuristics were used to determine the range of movements of the gauntlet as compared to the simplified hand model that I hand-created, and then slightly modified to give a better visual display response at the expense of some realism.  This meant that there was occasionally notable lag between moving the gauntlet into a position and actually having said position displayed on screen, and for some edge cases if the potentiometers got shifted the 3D model would clip into itself.  However, considering the extreme time constraints of only possessing the finsihed and wired gauntlet for two and a a half days and the fact that its ultimate purpose as a prototype was to serve as a proof of concept, I still think it served its purpose well.
